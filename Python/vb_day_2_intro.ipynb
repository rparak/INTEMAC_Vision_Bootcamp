{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Bootcamp - Day 2: Object Detection Using AI Techniques\n",
    "\n",
    "The second day of the **Vision Bootcamp** delves into modern approaches to **object detection** using **artificial intelligence (AI)** techniques. Participants will gain a deeper understanding of how machine learning algorithms, such as deep learning and convolutional neural networks (CNNs), can be applied to specific machine vision tasks. Practical examples will demonstrate how these technologies enable efficient and accurate object detection in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "In this first step, we import the necessary libraries that will be used throughout this workshop:\n",
    "\n",
    "- **OpenCV (`cv2`)**: This is the main library we’ll use for image processing tasks, such as reading, displaying, and manipulating images.\n",
    "- **NumPy (`np`)**: NumPy is a powerful library that helps with numerical operations, including matrix and array manipulations, which are essential in computer vision tasks.\n",
    "- **OS (`os`)**: This helps with file and directory operations, allowing us to load and save images from specific locations on your computer.\n",
    "\n",
    "This is the foundation for a smooth YOLO-based object detection workflow, and with these tools, we can start detecting objects in images using AI in an interactive and efficient way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV library for computer vision tasks\n",
    "import cv2\n",
    "\n",
    "# Numpy for numerical operations and handling arrays\n",
    "import numpy as np\n",
    "\n",
    "# OS module for file handling and accessing directories\n",
    "import os\n",
    "\n",
    "# User-defined utilities for smoother work with data\n",
    "import Utilities.General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Constants\n",
    "\n",
    "This script declares global constants and sets up the path to a specific dataset for training, validation, and testing in an object detection task using YOLO.\n",
    "\n",
    "### Machine Vision Stands\n",
    "\n",
    "Two different machine vision stands are available:\n",
    "\n",
    "- **Stand_1**:  \n",
    "  - Camera: Basler a2A2448-23gcPRO GigE Camera  \n",
    "  - Lighting: VMR-11566 Multi-Angle Ring Light  \n",
    "\n",
    "- **Stand_2**:  \n",
    "  - Camera: Basler a2A1920-51gcPRO GigE Camera  \n",
    "  - Lighting: EFFI-FD-200-200-000 High-Power Flat Light  \n",
    "\n",
    "### Configuration Parameters\n",
    "\n",
    "- **Camera Stand Name**: `Stand_1`, `Stand_2`\n",
    "- **Dataset Name**: `Dataset_v1`, `Dataset_v2`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file <../YOLO/Configuration/config_tmp.yaml> successfully updated and saved.\n"
     ]
    }
   ],
   "source": [
    "# HW setup of machine vision stands\n",
    "#   Stand_1: Basler a2A2448-23gcPRO GigE Camera; VMR-11566 Multi Angle Ring Light\n",
    "#   Stand_2: Basler a2A1920-51gcPRO GigE Camera; EFFI-FD-200-200-000 High-Power Flat Light\n",
    "\n",
    "# Name of the camera stand\n",
    "CONST_CAMERA_STAND_NAME = 'Stand_1'\n",
    "# Name of the dataset\n",
    "CONST_DATASET_NAME = 'Dataset_v1'\n",
    "\n",
    "# Get the full path to the dataset\n",
    "full_path = Utilities.General.Get_Full_Path(CONST_CAMERA_STAND_NAME, CONST_DATASET_NAME)\n",
    "\n",
    "# Ensure the dataset directory exists\n",
    "os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# Update the YAML configuration with the new path\n",
    "yaml_config_file = '../YOLO/Configuration/config_tmp.yaml'\n",
    "Utilities.General.Update_Yaml(yaml_config_file, full_path)\n",
    "\n",
    "# Select the desired size of YOLOv* to build the model\n",
    "#   Note:\n",
    "#     Detection Model\n",
    "#   Nano: 'yolov8n', Small: 'yolov8s', Medium: 'yolov8m', Large: 'yolov8l', XLarge: 'yolov8x'}\n",
    "CONST_YOLO_SIZE = 'yolov8n'\n",
    "# An indication of whether the backbone layers of the model should be frozen\n",
    "CONST_FREEZE_BACKBONE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Labeling Accuracy for Dataset Creation\n",
    "\n",
    "In this section, we test if the labeled data was successfully annotated by visualizing the bounding boxes on the image that is read from the file.\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. **Define paths**: Locate the project and dataset folders.\n",
    "2. **Create directories**: Ensure the dataset directory exists.\n",
    "3. **Load image and label data**: Read the image and corresponding label file.\n",
    "4. **Check image validity**: Verify the image exists and raise an error if not.\n",
    "5. **Convert image format**: Convert the image from BGR to RGB.\n",
    "6. **Draw bounding boxes**: Visualize YOLO-style bounding boxes on the image.\n",
    "7. **Save result**: Save and display the annotated image.\n",
    "\n",
    "This script helps verify that the image labeling was done correctly by visualizing the bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the path to the project folder\n",
    "project_folder = os.getcwd().split('Vision-Bootcamp')[0] + 'Vision-Bootcamp'\n",
    "\n",
    "# Define file path for the dataset location\n",
    "file_path = f'../Data/{CONST_CAMERA_STAND_NAME}/{CONST_DATASET_NAME}/'\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "# Define the path to the image and label file\n",
    "img_path_in = os.path.join(file_path, 'images/train/Image_1.png')\n",
    "label_path_in = os.path.join(file_path, 'labels/train/Image_1')\n",
    "\n",
    "# Load label data from the file\n",
    "label_data = Utilities.General.Load_Data(label_path_in, 'txt', ' ')\n",
    "\n",
    "# Load the image using OpenCV\n",
    "img_raw = cv2.imread(img_path_in)\n",
    "\n",
    "# Check if the image exists\n",
    "if img_raw is None:\n",
    "    raise FileNotFoundError(f'Image not found at {img_path_in}')\n",
    "\n",
    "# Convert the image from BGR to RGB color format\n",
    "img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get image dimensions\n",
    "img_height, img_width, _ = img_rgb.shape\n",
    "\n",
    "# Define a dictionary for class_id to color mapping\n",
    "class_colors = {0: (0, 255, 255), 1: (255, 0, 0)}  # Yellow and Blue in BGR\n",
    "\n",
    "# Draw bounding boxes\n",
    "for label_data_i in label_data:\n",
    "    # YOLO bounding box (class_id, x_center, y_center, width, height)\n",
    "    class_id, x_center, y_center, width, height = label_data_i\n",
    "\n",
    "    # Convert YOLO coordinates to pixel coordinates\n",
    "    x_c = int(x_center * img_width); y_c = int(y_center * img_height)\n",
    "    w = int(width * img_width); h = int(height * img_height)\n",
    "\n",
    "    # Calculate the top-left corner of the bounding box\n",
    "    x_top_left = int(x_c - w / 2); y_top_left = int(y_c - h / 2)\n",
    "    x_bottom_right = int(x_c + w / 2); y_bottom_right = int(y_c + h / 2)\n",
    "\n",
    "    # Get the bounding box color based on the class_id\n",
    "    class_id_color = class_colors.get(class_id, (0, 255, 0))  # Green as default\n",
    "\n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(img_raw, (x_top_left, y_top_left), (x_bottom_right, y_bottom_right), class_id_color, 2)\n",
    "\n",
    "# Define output image path\n",
    "output_path = os.path.join(f'../Data/{CONST_CAMERA_STAND_NAME}/Eval/', 'Image_1_result.png')\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "cv2.imwrite(output_path, img_raw)\n",
    "\n",
    "print(f'Result saved at: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation for Object Detection\n",
    "\n",
    "In this section, we apply data augmentation techniques to enhance the dataset for training an object detection model. The script performs the following tasks:\n",
    "\n",
    "1. **Define augmentation transformations**: Apply a series of transformations such as rotation, color jitter, Gaussian blur, and random resized crop to the images and their corresponding bounding boxes.\n",
    "2. **Generate augmented data**: The images and their annotations are processed and augmented multiple times based on a defined scaling factor (`CONST_SCALE_DATASET`).\n",
    "3. **Save augmented data**: The augmented images and their updated labels are saved in the specified dataset directory.\n",
    "4. **Progress display**: A progress bar (`tqdm`) is used to display the status of image augmentation.\n",
    "\n",
    "This script ensures that the dataset is enriched with augmented variations to improve the robustness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:06<00:00,  3.44image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:02<00:00,  2.87image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:07<00:00,  3.40image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:01<00:00,  3.24image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:07<00:00,  3.32image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:01<00:00,  3.15image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:06<00:00,  3.56image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:01<00:00,  3.19image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:17<00:00,  1.41image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:04<00:00,  1.28image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:17<00:00,  1.37image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:04<00:00,  1.45image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:16<00:00,  1.43image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:04<00:00,  1.37image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:11<00:00,  2.14image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:02<00:00,  2.95image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:05<00:00,  4.07image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:01<00:00,  4.11image/s]\n",
      "Augmenting <train> partition: 100%|██████████| 24/24 [00:05<00:00,  4.17image/s]\n",
      "Augmenting <valid> partition: 100%|██████████| 6/6 [00:01<00:00,  4.64image/s]\n"
     ]
    }
   ],
   "source": [
    "# Albumentations (Library for image augmentation) [pip3 install albumentations]\n",
    "import albumentations as A\n",
    "\n",
    "# tqdm (Progress bar library) for displaying the progress of iterations\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scaling factor for data augmentation of the dataset\n",
    "CONST_SCALE_DATASET = 10\n",
    "\n",
    "# Number of data in each partition of the dataset\n",
    "CONS_NUM_OF_DATA_IN_PARTITION = {'train': 24, 'valid': 6}\n",
    "\n",
    "# Define file path for the dataset location\n",
    "file_path = f'../Data/{CONST_CAMERA_STAND_NAME}/Dataset_v2/'\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "os.makedirs(file_path, exist_ok=True)  # Ensures the folder exists for storing the image\n",
    "\n",
    "# Transformation declaration with rotation\n",
    "transformation = A.Compose([\n",
    "    A.Affine(\n",
    "        translate_px={'x': (-50, 50), 'y': (-50, 50)},\n",
    "        rotate=(-10, 10),\n",
    "        p=0.75\n",
    "    ),\n",
    "    A.GaussianBlur(blur_limit=(5, 5), sigma_limit=(0.01, 1.0), p=0.5),\n",
    "    A.RandomResizedCrop(height=1544, width=2064, scale=(0.95, 1.0), p=0.5)\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "counter = 0\n",
    "while counter < CONST_SCALE_DATASET:\n",
    "    # Progress bar to show the current processing status\n",
    "    for key, value in CONS_NUM_OF_DATA_IN_PARTITION.items():\n",
    "        for j in tqdm(range(value), desc=f'Iteration <{counter+1}>; Augmenting <{key}> partition', unit='image'):\n",
    "            index = (list(CONS_NUM_OF_DATA_IN_PARTITION.keys()).index(key) * CONS_NUM_OF_DATA_IN_PARTITION['train']) + j + 1\n",
    "            img_path_in = os.path.join(file_path, f'images/{key}/Image_{index}.png')\n",
    "            label_path_in = os.path.join(file_path, f'labels/{key}/Image_{index}')\n",
    "            \n",
    "            try:\n",
    "                # Load label data from the file\n",
    "                label_data = Utilities.General.Load_Data(label_path_in, 'txt', ' ')\n",
    "\n",
    "                # Load the image using OpenCV\n",
    "                img_raw = cv2.imread(img_path_in)\n",
    "\n",
    "                # Check if the image exists\n",
    "                if img_raw is None:\n",
    "                    print(f'Warning: Image not found at {img_path_in}')  # Add more informative error\n",
    "                    continue  # Skip this iteration if the image is not found\n",
    "\n",
    "                # Get image dimensions\n",
    "                img_height, img_width, _ = img_raw.shape\n",
    "\n",
    "                # Apply augmentation to image and bounding boxes\n",
    "                augmented = transformation(image=img_raw, bboxes=label_data[:, 1:], class_labels=label_data[:, 0].T)\n",
    "\n",
    "                # Save the augmented image\n",
    "                cv2.imwrite(os.path.join(file_path, f'images/{key}/Image_{index}_Aug_{counter+1}.png'), augmented['image'])\n",
    "\n",
    "                # Prepare label data for saving\n",
    "                v = np.array(augmented['class_labels']).reshape(-1, 1)  # Reshape to column vector\n",
    "                M = np.array(augmented['bboxes'])\n",
    "\n",
    "                # Convert NumPy array to space-separated string, ensuring the first value is an integer\n",
    "                formatted_output = '\\n'.join(\n",
    "                    f'{int(row[0])} ' + ' '.join(f'{val:.6f}' for val in row[1:])\n",
    "                    for row in np.hstack((v, M))\n",
    "                )\n",
    "\n",
    "                # Save the label data (bounding box) to a file\n",
    "                Utilities.General.Save_Data(os.path.join(file_path, f'labels/{key}/Image_{index}_Aug_{counter+1}'), formatted_output, 'txt', '')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error processing {img_path_in}: {e}')\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "In this step, we import the necessary libraries that will be used throughout this workshop:\n",
    "\n",
    "- **Ultralytics (`YOLO`)**: This library provides real-time object detection and image segmentation capabilities. It enables us to use the YOLO model for accurate and efficient object detection.\n",
    "\n",
    "This is the foundation for a smooth OpenCV workflow, and with these tools, we can start manipulating images in an interactive and fun way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultralytics (Real-time object detection and image segmentation \n",
    "# model) [pip install ultralytics]\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Function to freeze the backbone layers of the model\n",
    "from Utilities.Model import Freeze_Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Custom YOLO Model\n",
    "\n",
    "In this section, we set up and train a custom YOLOv8 model on a specific dataset. The script performs the following steps:\n",
    "\n",
    "1. **Check and remove existing YOLO model**: If a pre-trained model already exists, it is removed to ensure a fresh training session.\n",
    "2. **Load pre-trained YOLO model**: A pre-trained YOLOv8 model is loaded from the specified directory.\n",
    "3. **Freeze backbone (optional)**: If the `CONST_FREEZE_BACKBONE` flag is set to `True`, the backbone of the model is frozen during training.\n",
    "4. **Train the model**: The YOLO model is trained using the provided dataset configuration, with specified parameters like image size (`640x640`), number of epochs (`100`), and other training settings.\n",
    "\n",
    "This script prepares the model and trains it on the custom dataset to perform object detection tasks.\n",
    "\n",
    "Training the YOLOv8 model on a custom dataset allows the model to learn specific object detection tasks using the dataset and hyperparameters defined for the task.\n",
    "\n",
    "For more information, see: [YOLOv8 Training Documentation](https://docs.ultralytics.com/modes/train/#arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Locate the path to the project folder\n",
    "project_folder = os.getcwd().split('Vision-Bootcamp')[0] + 'Vision-Bootcamp'\n",
    "\n",
    "# Remove the YOLO model, if it already exists\n",
    "if os.path.isfile(f'../YOLO/Model/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/{CONST_YOLO_SIZE}.pt'):\n",
    "    print(f'[INFO] Removing the YOLO model.')\n",
    "    os.remove(f'../YOLO/Model/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/{CONST_YOLO_SIZE}.pt')\n",
    "\n",
    "# Load a pre-trained YOLO model\n",
    "model = YOLO(f'../YOLO/Model/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/{CONST_YOLO_SIZE}.pt')\n",
    "\n",
    "if CONST_FREEZE_BACKBONE == True:\n",
    "    # Triggered when the training starts\n",
    "    model.add_callback('on_train_start', Freeze_Backbone)\n",
    "\n",
    "# Training the model on a custom dataset with additional dependencies (number of epochs, image size, etc.)\n",
    "model.train(data=f'{project_folder}/YOLO/Configuration/config_tmp.yaml', batch=-1, imgsz=640, epochs=100, patience=0,\n",
    "            rect=True, name=f'{project_folder}/YOLO/Results/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/train_fb_{CONST_FREEZE_BACKBONE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of a Custom YOLO Model on Test Dataset\n",
    "\n",
    "In this section, we validate a pre-trained YOLOv8 model on a test dataset. The script performs the following steps:\n",
    "\n",
    "1. **Load pre-trained YOLO model**: The best weights of the trained YOLOv8 model are loaded from the specified checkpoint directory.\n",
    "2. **Evaluate performance**: The model is evaluated on the test dataset using a confidence threshold (`0.001`) and an IoU threshold (`0.6`), measuring its accuracy and generalization performance.\n",
    "3. **Save results**: The results of the evaluation are saved, including image outputs, bounding box coordinates, confidence scores, and other relevant metrics.\n",
    "\n",
    "This script helps measure the accuracy of the trained model on the test set and stores the results for further analysis.\n",
    "\n",
    "Validation of the YOLOv8 model after training allows us to assess its performance and fine-tune the model if necessary.\n",
    "\n",
    "For more information, see: [YOLOv8 Validation Documentation](https://docs.ultralytics.com/modes/val/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained custom YOLO model.\n",
    "model = YOLO(f'{project_folder}/YOLO/Results/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/train_fb_{CONST_FREEZE_BACKBONE}/weights/best.pt')\n",
    "\n",
    "# Evaluate the performance of the model on the validation dataset.\n",
    "model.val(data=f'{project_folder}/YOLO/Configuration/config_tmp.yaml', batch=32, imgsz=640, conf=0.001, iou=0.6, rect=True, \n",
    "          save_txt=True, save_conf=True, save_json=False, split='test', name=f'{project_folder}/YOLO/Results/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/valid_fb_{CONST_FREEZE_BACKBONE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction (Testing) using the YOLOv8 Model on Test Dataset\n",
    "\n",
    "In this section, we perform prediction (testing) using a trained YOLOv8 model on new images. The script performs the following steps:\n",
    "\n",
    "1. **Load pre-trained YOLO model**: The best weights of the trained YOLOv8 model are loaded from the specified checkpoint file.\n",
    "2. **Make predictions**: The model makes predictions on images from the test dataset, predicting both the classes and locations of objects in the input images. The confidence threshold is set to `0.5`, and the IoU threshold is `0.7`.\n",
    "3. **Save results**: The predictions are saved as image outputs with bounding boxes, and the corresponding class labels and confidence scores are stored in text files.\n",
    "\n",
    "For more information, see: [YOLOv8 Prediction Documentation](https://docs.ultralytics.com/modes/predict/)\n",
    "\n",
    "This script helps evaluate the model's performance on the test set and stores the prediction results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained custom YOLO model.\n",
    "model = YOLO(f'{project_folder}/YOLO/Results/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/train_fb_{CONST_FREEZE_BACKBONE}/weights/best.pt')\n",
    "\n",
    "# Predict (test) the model on a test dataset.\n",
    "model.predict(source=f'{project_folder}/Data/{CONST_CAMERA_STAND_NAME}/{CONST_DATASET_NAME}/images/test', save=True, save_txt=True, save_conf=True, \n",
    "              imgsz=[480, 640], conf=0.5, iou=0.7, name=f'{project_folder}/YOLO/Results/{CONST_CAMERA_STAND_NAME}_{CONST_DATASET_NAME}/predict_fb_{CONST_FREEZE_BACKBONE}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_vb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
