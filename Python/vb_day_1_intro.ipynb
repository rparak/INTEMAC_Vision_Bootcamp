{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Bootcamp - Day 1: Introduction to Machine Vision and Camera Systems\n",
    "\n",
    "The first day of the **Vision Bootcamp** focuses on the fundamentals of **machine vision** and introduces key technologies in the field. Participants will learn about the core principles of machine vision, its practical applications, and how to effectively use hardware (such as cameras and sensors) and software tools for image processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "In this first step, we import the necessary libraries that will be used throughout this workshop:\n",
    "\n",
    "- **OpenCV (`cv2`)**: This is the main library we’ll use for image processing tasks, such as reading, displaying, and manipulating images.\n",
    "- **Matplotlib (`plt`)**: We use this library for plotting images and displaying results inside the notebook.\n",
    "- **NumPy (`np`)**: NumPy is a powerful library that helps with numerical operations, including matrix and array manipulations, which are essential in computer vision tasks.\n",
    "- **OS (`os`)**: This helps with file and directory operations, allowing us to load and save images from specific locations on your computer.\n",
    "- **ipywidgets**: This library enables us to create interactive widgets like sliders and buttons, making it easier to visualize changes in real-time.\n",
    "\n",
    "This is the foundation for a smooth OpenCV workflow, and with these tools, we can start manipulating images in an interactive and fun way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "# OpenCV library for computer vision tasks\n",
    "import cv2\n",
    "\n",
    "# Matplotlib for plotting and displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numpy for numerical operations and handling arrays\n",
    "import numpy as np\n",
    "\n",
    "# OS module for file handling and accessing directories\n",
    "import os\n",
    "\n",
    "# ipywidgets for interactive elements like sliders and buttons in the notebook\n",
    "from ipywidgets import interact, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Displaying an Image\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. **Define the file path** where the image is stored.\n",
    "2. **Ensure the directory exists**: If the directory where the image is located doesn't exist, it will be created automatically with `os.makedirs(file_path, exist_ok=True)`.\n",
    "3. **Load the image**: We use `cv2.imread()` to load the image from the specified path. If the image cannot be found, we raise a `FileNotFoundError`.\n",
    "4. **Convert the image color**: OpenCV reads images in BGR format (Blue, Green, Red). Since `matplotlib` works with RGB format (Red, Green, Blue), we convert the image using `cv2.cvtColor()`.\n",
    "5. **Display the image**: The image is displayed using `matplotlib`'s `imshow()` function, and we adjust the layout and remove axis ticks for a clean view of the image.\n",
    "   \n",
    "This process is crucial in any computer vision workflow where you load and display images for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW setup of machine vision stands\n",
    "#   Stand_1: Basler a2A2448-23gcPRO GigE Camera; VMR-11566 Multi Angle Ring Light\n",
    "#   Stand_2: Basler a2A1920-51gcPRO GigE Camera; EFFI-FD-200-200-000 High-Power Flat Light\n",
    "\n",
    "# Define file path for the image location\n",
    "file_path = '../Data/Stand_1/Raw'\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "os.makedirs(file_path, exist_ok=True)  # Ensures the folder exists for storing the image\n",
    "\n",
    "# Define the path to the image file\n",
    "img_path_in = os.path.join(file_path, 'Image_1.png')\n",
    "\n",
    "# Load the image using OpenCV\n",
    "img_raw = cv2.imread(img_path_in)\n",
    "\n",
    "# Check if the image exists\n",
    "if img_raw is None:\n",
    "    # Raise error if the image isn't found\n",
    "    raise FileNotFoundError(f'Image not found at {img_path_in}')\n",
    "\n",
    "# Convert the image from BGR to RGB color format\n",
    "img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Set up the plot with a larger figure size to display images clearly\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Title for the displayed image\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Hide axis marks for better image view\n",
    "plt.axis('off')\n",
    "\n",
    "# Adjust layout for better presentation\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing: Resize, Rotate, and Crop\n",
    "\n",
    "In this section, we will perform some basic image transformations using OpenCV and visualize the results. We will:\n",
    "\n",
    "1. **Check if the image exists**: We ensure the image is loaded correctly by checking if `img_rgb` is `None`.\n",
    "2. **Resize the image**: The image is resized to 1/4th of its original size using `cv2.resize()`. We print the shape of the original and resized images for comparison.\n",
    "3. **Rotate the image**: The image is rotated by 15 degrees around its center using `cv2.getRotationMatrix2D()` to get the rotation matrix, and then applying the rotation with `cv2.warpAffine()`.\n",
    "4. **Crop the image**: Although this example uses the full image, we show how to crop the image by defining specific coordinates (`y_1:y_2, x_1:x_2`). You can modify the values to crop different parts of the image.\n",
    "5. **Display the results**: The original, rotated, and cropped images are displayed side by side using `matplotlib`, so we can visually compare the effects of the transformations.\n",
    "\n",
    "This exercise demonstrates basic image manipulation techniques that are foundational in computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image exists before processing\n",
    "if img_rgb is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the original image to work with\n",
    "img_tmp = img_rgb.copy()\n",
    "\n",
    "# Resize the image by scaling it down to 1/4th of the original size\n",
    "print(f'Original Image shape: {img_tmp.shape}')\n",
    "img_resized = cv2.resize(img_tmp, (img_tmp.shape[1] // 4, img_tmp.shape[0] // 4))\n",
    "\n",
    "print(f'Resized Image shape: {img_resized.shape}')\n",
    "\n",
    "# Rotate the image by 15 degrees\n",
    "alpha = 15.0  # Angle of rotation in degrees\n",
    "(h, w) = img_tmp.shape[:2]  # Get the height and width of the image\n",
    "center = (w // 2, h // 2)  # Find the center of the image\n",
    "\n",
    "# Get the rotation matrix for rotating the image\n",
    "R = cv2.getRotationMatrix2D(center, alpha, 1.0)  # 1.0 is the scale factor for the image\n",
    "img_rotated = cv2.warpAffine(img_tmp, R, (w, h))  # Apply the rotation matrix to the image\n",
    "\n",
    "# Crop the image using the defined crop coordinates (y1:y2, x1:x2)\n",
    "y_1 = 850; y_2 = h-900; x_1 = 1150; x_2 = w-1150\n",
    "img_cropped = img_tmp[y_1:y_2, x_1:x_2]\n",
    "\n",
    "print(f'Cropped Image shape: {img_cropped.shape}')\n",
    "\n",
    "# Set up the plot to display images side by side for comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Display the original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_tmp)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the rotated image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_rotated)\n",
    "plt.title('Rotated Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the cropped image\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_cropped)\n",
    "plt.title('Cropped Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Adjust layout and display all images side by side\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Image Contrast and Brightness\n",
    "\n",
    "In this section, we provide an interactive way to adjust the **contrast** and **brightness** of the image using sliders. Here’s how it works:\n",
    "\n",
    "1. **Checking if the image exists**: We first ensure that the image is loaded correctly. If it’s not, we raise an error.\n",
    "2. **Creating a temporary copy of the image**: This step avoids altering the original image directly by working on a copy.\n",
    "3. **The `Update_Img_Alpha_Beta` function**: This function dynamically updates the image’s contrast and brightness:\n",
    "    - **Contrast (`alpha`)**: The contrast of the image is adjusted by scaling the pixel values. A value of `alpha = 1.0` means no change, while higher values increase contrast.\n",
    "    - **Brightness (`beta`)**: The brightness of the image is adjusted by adding or subtracting pixel values. A value of `beta = 0` means no change, and values above or below 0 lighten or darken the image respectively.\n",
    "    - The function uses OpenCV’s `cv2.convertScaleAbs()` to apply these adjustments to the image.\n",
    "4. **Interactive sliders**: We use `ipywidgets.FloatSlider` to create sliders that control the contrast and brightness. The `alpha` slider adjusts the contrast, and the `beta` slider adjusts the brightness.\n",
    "5. **Displaying the images**: The original image is displayed on the left, and the modified image is shown on the right so that users can see the real-time changes side by side.\n",
    "6. **`interact` function**: The `interact` function from `ipywidgets` allows for interactive widget controls. When the user moves the sliders, the `Update_Img_Alpha_Beta` function is automatically called to update the images.\n",
    "\n",
    "This interactive approach helps users visually understand how adjusting contrast and brightness affects the image in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image exists before processing\n",
    "if img_rgb is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the original image to work with\n",
    "img_tmp = img_rgb.copy()\n",
    "\n",
    "# Set up the plot to display images side by side\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Function to update image contrast and brightness\n",
    "def Update_Img_Alpha_Beta(alpha, beta):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Function adjusts the contrast and brightness of the image based on the slider values \n",
    "        for alpha (contrast) and beta (brightness).\n",
    "    \"\"\"\n",
    "\n",
    "    # Adjust the contrast and brightness using OpenCV's convertScaleAbs method\n",
    "    img_modified = cv2.convertScaleAbs(img_tmp, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Display the original image on the left\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_tmp)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the modified image on the right\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_modified)\n",
    "    plt.title('Modified Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Adjust layout and show both images side by side\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create sliders for adjusting contrast (alpha) and brightness (beta)\n",
    "alpha_s = FloatSlider(value=1.0, min=0.0, max=10.0, step=0.01, description='Contrast')\n",
    "beta_s = FloatSlider(value=0.0, min=-200.0, max=200.0, step=0.1, description='Brightness')\n",
    "\n",
    "# Link the sliders to the update function using 'interact'\n",
    "interact(Update_Img_Alpha_Beta, alpha=alpha_s, beta=beta_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Color Segmentation Using HSV with Optional Gaussian Blur\n",
    "\n",
    "In this interactive section, we will explore color segmentation in the HSV (Hue, Saturation, Value) color space. This allows us to isolate specific colors in an image based on adjustable thresholds.\n",
    "\n",
    "### Steps Involved:\n",
    "\n",
    "1. **Image Validation**: First, we ensure the image is loaded correctly before processing.\n",
    "2. **HSV Conversion**: The image is converted from RGB to the HSV color space for more intuitive color segmentation.\n",
    "3. **Optional Filtering**: A **Gaussian Blur** can be applied to smooth the image and reduce noise, which often improves color segmentation results.\n",
    "4. **Adjust HSV Range**: Use the sliders to adjust the minimum and maximum values for Hue, Saturation, and Value. These ranges control what parts of the image will be included in the segmentation.\n",
    "   - **Hue**: Controls the color of the image.\n",
    "   - **Saturation**: Controls how intense or washed out the color is.\n",
    "   - **Value**: Controls the brightness of the color.\n",
    "5. **Real-time Results**: The **HSV mask** is displayed alongside the filtered image, showing which parts of the image match the specified color range.\n",
    "\n",
    "### How to Use:\n",
    "- **Gaussian Blur**: You can choose to apply a Gaussian Blur to smooth the image. This can help reduce noise and improve the accuracy of segmentation.\n",
    "- **Adjusting HSV Sliders**: Experiment with the sliders for Hue, Saturation, and Value to isolate different colors in the image.\n",
    "- **View the Results**: The left image shows the filtered image (with or without Gaussian Blur), while the right image displays the mask created by the selected color range.\n",
    "\n",
    "This interactive setup provides a hands-on way to learn about color segmentation and the importance of the HSV color space for tasks such as object detection and background removal.\n",
    "\n",
    "---\n",
    "This interactive method helps participants explore the effect of different color ranges and understand how image segmentation works in a real-time visual context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image exists before processing\n",
    "if img_rgb is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the original image to work with\n",
    "img_tmp = img_rgb.copy()\n",
    "\n",
    "# Function to update the image using cv2.inRange for HSV color space\n",
    "def Update_Img_HSV_Range(hue_min, hue_max, sat_min, sat_max, val_min, val_max, filter_type):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Function apply a filter (optional) and create a mask for the given HSV range.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply the selected filter\n",
    "    if filter_type == 'Gaussian Blur':\n",
    "        # Apply Gaussian Blur to reduce noise\n",
    "        img_filtered = cv2.GaussianBlur(img_tmp, (5, 5), cv2.BORDER_DEFAULT)\n",
    "    else:\n",
    "        # No filter applied\n",
    "        img_filtered = img_tmp \n",
    "\n",
    "    # Define the range for Hue, Saturation, and Value\n",
    "    lower_bound = (hue_min, sat_min, val_min)\n",
    "    upper_bound = (hue_max, sat_max, val_max)\n",
    "\n",
    "    # Convert the image to HSV\n",
    "    image_hsv = cv2.cvtColor(img_filtered, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Use cv2.inRange() to create a mask based on the HSV range\n",
    "    mask = cv2.inRange(image_hsv, lower_bound, upper_bound)\n",
    "    \n",
    "    # Set up the plot to display images side by side\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Display the original image with filter applied\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_filtered)\n",
    "    plt.title(f'Filtered Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Display the HSV mask\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title('HSV Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show all images side by side\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create sliders for Hue, Saturation, and Value thresholds\n",
    "hue_min_s = FloatSlider(value=0.0, min=0.0, max=179.0, step=1.0, description='Hue (-)')\n",
    "hue_max_s = FloatSlider(value=179.0, min=0.0, max=179.0, step=1.0, description='Hue (+)')\n",
    "sat_min_s = FloatSlider(value=0.0, min=0.0, max=255.0, step=1.0, description='Sat (-)')\n",
    "sat_max_s = FloatSlider(value=255.0, min=0.0, max=255.0, step=1.0, description='Sat (+)')\n",
    "val_min_s = FloatSlider(value=0.0, min=0.0, max=255.0, step=1.0, description='Val (-)')\n",
    "val_max_s = FloatSlider(value=255.0, min=0.0, max=255.0, step=1.0, description='Val (+)')\n",
    "\n",
    "# Create a dropdown for selecting filter type\n",
    "filter_type_s = ['None', 'Gaussian Blur']\n",
    "\n",
    "# Use interact to link sliders to the update function\n",
    "interact(Update_Img_HSV_Range, hue_min=hue_min_s, hue_max=hue_max_s, \n",
    "         sat_min=sat_min_s, sat_max=sat_max_s, \n",
    "         val_min=val_min_s, val_max=val_max_s,\n",
    "         filter_type=filter_type_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Color Segmentation in HSV Space\n",
    "\n",
    "In this section, we will learn how to segment any color in an image using the **HSV color space**. Instead of focusing on a specific color, we will allow users to select the **Hue**, **Saturation**, and **Value** ranges interactively. This will enable us to isolate **any color** from the image, not just yellow.\n",
    "\n",
    "### Steps Involved:\n",
    "\n",
    "1. **Gaussian Blur**: First, we apply a **Gaussian Blur** to reduce noise in the image. This makes the color segmentation process more effective by reducing small noise that might affect the mask.\n",
    "\n",
    "2. **Convert to HSV**: We convert the image to the **HSV color space**, which is better for color segmentation compared to RGB. This is because the **Hue** channel represents color directly, while **Saturation** and **Value** control the intensity and brightness of the color.\n",
    "\n",
    "3. **Color Mask Creation**: Using the `cv2.inRange()` function, we create a mask that highlights pixels that fall within the specified color range. You will be able to adjust these ranges interactively to segment different colors in the image.\n",
    "\n",
    "4. **Apply the Mask**: The mask is applied to the image, and the result is an image that only shows the regions that match the selected color.\n",
    "\n",
    "### Visualizing the Process:\n",
    "- **Filtered Image**: This is the image after applying Gaussian Blur. It smooths out small details and noise.\n",
    "- **Color Mask**: The mask is a binary image that shows the areas where the selected color is present in the image. The white regions represent the color match, while the black areas are ignored.\n",
    "- **Masked Image**: The final image, where only the regions that match the selected color are kept, and the rest is masked out.\n",
    "\n",
    "---\n",
    "\n",
    "This technique can be applied to segment any color from the image by adjusting the **Hue**, **Saturation**, and **Value** ranges interactively. You can experiment with different values to see how the segmentation changes, making it a powerful tool for color-based image analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image exists before processing\n",
    "if img_rgb is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the original image to work with\n",
    "img_tmp = img_rgb.copy()\n",
    "\n",
    "# Apply Gaussian Blur to reduce noise and smooth the image\n",
    "img_filtered = cv2.GaussianBlur(img_tmp, (5, 5), 0)\n",
    "\n",
    "# Convert the image to HSV (Hue, Saturation, Value) color space\n",
    "img_hsv = cv2.cvtColor(img_filtered, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# Create a mask for a specific color range in HSV space\n",
    "# The values '(hue_min, sat_min, val_min), (hue_max, sat_max, val_max)' will be obtained interactively during the workshop\n",
    "hue_min = 0.0; sat_min = 0.0; val_min = 175.0\n",
    "hue_max = 179.0; sat_max = 255.0; val_max = 255.0\n",
    "mask = cv2.inRange(img_hsv, (hue_min, sat_min, val_min), (hue_max, sat_max, val_max))\n",
    "\n",
    "# Apply the mask to the filtered image to extract the desired color regions\n",
    "image_hsv = cv2.bitwise_and(img_filtered, img_filtered, mask=mask)\n",
    "\n",
    "# Set up the plot to display images side by side for comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Display the filtered image (after Gaussian Blur)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_filtered)\n",
    "plt.title('Filtered Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the color mask\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('Color Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the result of applying the mask (HSV image with color regions)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(image_hsv)\n",
    "plt.title('Masked Image (Selected Color Regions)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Adjust layout and display all images side by side\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Histograms: Understanding Image Intensities in Red, Green, and Blue Channels\n",
    "\n",
    "In this section of the workshop, we will explore how to visualize the intensity distribution of pixels in the **Red**, **Green** and **Blue** channels of an image. Color histograms are useful in image analysis, as they allow us to understand the distribution of colors and intensities within an image.\n",
    "\n",
    "### Steps Involved:\n",
    "\n",
    "1. **Split the Image into Color Channels**:\n",
    "   - We start by splitting the **HSV** image (which could be based on a previous color segmentation) into the **Red**, **Green** and **Blue** channels using the `cv2.split()` function. This enables us to examine how each color contributes to the final image.\n",
    "\n",
    "2. **Exclude Black Pixels**:\n",
    "   - Black pixels (intensity = 0) are not useful when calculating histograms, so we exclude them using a mask. The mask ensures that only non-black pixels are considered in the histogram calculation.\n",
    "\n",
    "3. **Calculate Histograms**:\n",
    "   - The **histogram** of each color channel is computed using `cv2.calcHist()`. This function counts the frequency of each pixel intensity (from 0 to 255) in each of the color channels.\n",
    "\n",
    "4. **Plotting the Histograms**:\n",
    "   - We plot the **histograms** for each channel using `matplotlib`, showing the pixel intensity distribution for **Red**, **Green** and **Blue** channels separately.\n",
    "\n",
    "### What Do the Histograms Tell Us?\n",
    "\n",
    "- The histograms show how the intensity values of each color (Red, Blue, Green) are distributed across the image.\n",
    "- A high peak in a particular color's histogram indicates that this color is more prominent in the image.\n",
    "- Conversely, a flat or low histogram indicates that the color is less significant in the image.\n",
    "\n",
    "### Visualizing the Process:\n",
    "\n",
    "- The **Red**, **Green**, and **Blue histograms** help us understand how each channel contributes to the final color appearance of the image. \n",
    "- By analyzing these histograms, you can also learn how to manipulate image contrast, saturation, and brightness by modifying the intensity distributions.\n",
    "\n",
    "---\n",
    "\n",
    "This exercise helps in visualizing how individual colors contribute to the overall appearance of the image. Understanding color histograms is essential for tasks like color correction, color segmentation, and image enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'image_hsv' is already created using cv2.bitwise_and()\n",
    "# Check if the image exists before processing\n",
    "if image_hsv is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the image to work with\n",
    "img_tmp = image_hsv.copy()\n",
    "\n",
    "# Split the image into Red, Green, and Blue channels\n",
    "(red, green, blue) = cv2.split(image_hsv)\n",
    "\n",
    "# Mask to exclude black pixels (0 intensity) for histogram calculation\n",
    "non_black_mask = (red > 0) | (blue > 0) | (green > 0)\n",
    "\n",
    "# Calculate the histograms for each channel, excluding black pixels\n",
    "red_hist = cv2.calcHist([red[non_black_mask]], [0], None, [256], [0, 256])\n",
    "green_hist = cv2.calcHist([green[non_black_mask]], [0], None, [256], [0, 256])\n",
    "blue_hist = cv2.calcHist([blue[non_black_mask]], [0], None, [256], [0, 256])\n",
    "\n",
    "# Plot the histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(red_hist, color='red', label='Red Channel')\n",
    "plt.plot(green_hist, color='green', label='Green Channel')\n",
    "plt.plot(blue_hist, color='blue', label='Blue Channel')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Color Histograms')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Show the histogram plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour Detection and Shape Analysis\n",
    "\n",
    "In this part of the workshop, we'll explore **contour detection** using OpenCV, focusing on how to find and analyze the shapes of objects in an image. We'll also calculate important properties like **area**, **aspect ratio**, and **perimeter** for the detected contours.\n",
    "\n",
    "### Steps Involved:\n",
    "\n",
    "1. **Threshold the Mask**:\n",
    "   - We start by ensuring that the mask is binary (only 0 or 255 values) using `cv2.threshold()`. This is important for contour detection since it allows OpenCV to distinguish between the object and the background.\n",
    "\n",
    "2. **Find Contours**:\n",
    "   - Using `cv2.findContours()`, we detect the contours in the binary image. A contour is essentially a curve that joins all the continuous points along a boundary that have the same color or intensity.\n",
    "\n",
    "3. **Bounding Boxes**:\n",
    "   - For each detected contour, we calculate the **bounding box** (a rectangle that tightly encloses the contour). This allows us to visualize the region of interest and analyze its shape.\n",
    "\n",
    "4. **Aspect Ratio & Perimeter**:\n",
    "   - We compute the **aspect ratio** of the bounding box (width/height), which can be useful in distinguishing between different shapes. The **perimeter** is also calculated for each contour, which gives us the total length of the contour’s boundary.\n",
    "\n",
    "5. **Contour Visualization**:\n",
    "   - The contours and bounding boxes are drawn on the image to visualize the detected shapes. This step allows us to see how OpenCV detects and analyzes objects in the image.\n",
    "\n",
    "### Interactive Exploration:\n",
    "Participants can experiment with adjusting the area threshold (`500` in this case) to see how different object sizes are detected. They can also explore the effect of adjusting contour properties like aspect ratio and perimeter on object classification.\n",
    "\n",
    "### What Does This Teach Us?\n",
    "- **Contour Detection** helps in identifying and extracting meaningful regions in an image.\n",
    "- **Bounding Boxes** provide a quick way to locate objects in the image and analyze their shape.\n",
    "- **Aspect Ratio** and **Perimeter** are useful for shape analysis, particularly when identifying or classifying different objects.\n",
    "\n",
    "This technique is fundamental in **object detection**, **robot vision**, **autonomous systems**, and other image analysis applications.\n",
    "\n",
    "---\n",
    "By visualizing and analyzing contours, we can gain insights into the structure and size of objects, which is an essential step in many image processing and computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'image_rgb' is already loaded as your image (e.g., via cv2.imread) and 'mask' is already created using cv2.inRange()\n",
    "\n",
    "# Check if the image exists before processing\n",
    "if img_rgb is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the original image to work with\n",
    "img_tmp = img_rgb.copy()\n",
    "\n",
    "# Check if the mask exists before processing\n",
    "if mask is None:\n",
    "    raise ValueError('Error: The mask is empty or not created correctly!')\n",
    "\n",
    "# Create a temporary copy of the mask\n",
    "mask_tmp = mask.copy()\n",
    "\n",
    "# Apply thresholding to ensure mask is binary (if it's not already)\n",
    "_, thresh = cv2.threshold(mask_tmp, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary image (thresh)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Copy the original image to draw contours and bounding boxes on it\n",
    "img_registred_1 = img_tmp.copy()\n",
    "\n",
    "# Loop through each contour\n",
    "for contour in contours:\n",
    "    # Get the area of the contour\n",
    "    area = cv2.contourArea(contour)\n",
    "\n",
    "    # If the contour is too small, ignore it (adjust area threshold based on your use case)\n",
    "    if area < 50:  \n",
    "        # Area threshold to avoid noise or small irrelevant contours\n",
    "        continue\n",
    "\n",
    "    # Get the bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Draw the contour and the bounding box on the image\n",
    "    cv2.drawContours(img_registred_1, [contour], -1, (0, 255, 0), 5)\n",
    "    cv2.rectangle(img_registred_1, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "\n",
    "    # Calculate the aspect ratio (width / height) and the perimeter of the contour\n",
    "    aspect_ratio = w / h; perimeter = cv2.arcLength(contour, True)\n",
    "    print(f'Area: {area}, Aspect Ratio: {aspect_ratio}, Perimeter: {perimeter}')\n",
    "\n",
    "# Show the result with contours and shape analysis (bounding boxes and contours drawn)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img_registred_1)\n",
    "plt.title('Contour and Shape Analysis')\n",
    "plt.axis('off')\n",
    "\n",
    "# Adjust layout and display all images side by side\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Matching and Object Detection\n",
    "\n",
    "Template matching is a technique used in **computer vision** to find a small image (template) within a larger image. It's useful for object detection and recognizing patterns in an image. \n",
    "\n",
    "### Steps to Perform Template Matching:\n",
    "1. **Convert to Grayscale**: \n",
    "   - Both the main image and the template are converted to grayscale, which simplifies the comparison process and speeds up template matching.\n",
    "\n",
    "2. **Apply Template Matching**: \n",
    "   - We use `cv2.matchTemplate()` to compare the template with the larger image. It slides the template over the image and computes a similarity score at each position.\n",
    "\n",
    "3. **Thresholding**: \n",
    "   - The similarity scores are thresholded to find the regions of the image where the template matches well.\n",
    "\n",
    "4. **Non-Maximum Suppression (NMS)**: \n",
    "   - We apply NMS to remove overlapping bounding boxes, keeping only the most prominent matches.\n",
    "\n",
    "5. **Bounding Boxes**: \n",
    "   - Rectangles are drawn around the detected matches on the original image.\n",
    "\n",
    "### Practical Applications:\n",
    "- **Object Detection**: Identifying and locating objects within images.\n",
    "- **Pattern Recognition**: Finding patterns or shapes that match a template.\n",
    "- **Tracking**: Following objects across frames in video processing.\n",
    "\n",
    "### Interactive Exploration:\n",
    "Participants can change the template image and the threshold value to see how template matching responds to different objects and match quality.\n",
    "\n",
    "By the end of this exercise, participants will be familiar with template matching and its application in real-world computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'image_rgb' is already loaded as your image (e.g., via cv2.imread) and 'img_cropped' is already created\n",
    "\n",
    "# Check if the image exists before processing\n",
    "if img_rgb is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the original image to work with\n",
    "img_tmp = img_rgb.copy()\n",
    "\n",
    "# Check if the cropped image (template) exists before processing\n",
    "if img_cropped is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Create a temporary copy of the cropped image (template)\n",
    "img_cropped_tmp = img_cropped.copy()\n",
    "\n",
    "# Convert both images to grayscale\n",
    "image = cv2.cvtColor(img_tmp, cv2.COLOR_RGB2GRAY)\n",
    "template = cv2.cvtColor(img_cropped_tmp, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Get the dimensions of the template\n",
    "template_height, template_width = template.shape\n",
    "\n",
    "# Perform template matching using cv2.matchTemplate()\n",
    "result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Set a threshold value for the matches (e.g., 0.8)\n",
    "threshold = 0.8\n",
    "locations = np.where(result >= threshold)  # Find all locations where match value exceeds threshold\n",
    "\n",
    "# Convert locations to a list of (x, y) points\n",
    "locations = list(zip(*locations[::-1]))  # Reverse to get (x, y) format\n",
    "\n",
    "# Use Non-Maximum Suppression (NMS) to remove overlapping boxes\n",
    "filtered_rects = []\n",
    "for loc in locations:\n",
    "    x, y = loc\n",
    "    should_add = True\n",
    "    \n",
    "    # Check if this match is too close to an existing match\n",
    "    for (fx, fy) in filtered_rects:\n",
    "        if abs(fx - x) < template_width and abs(fy - y) < template_height:\n",
    "            should_add = False\n",
    "            break\n",
    "        \n",
    "    if should_add:\n",
    "        filtered_rects.append((x, y))\n",
    "\n",
    "# Copy the original image to draw rectangles around the matches\n",
    "img_registred_2 = img_tmp.copy()\n",
    "\n",
    "# Draw rectangles around the filtered matches\n",
    "for (x, y) in filtered_rects:\n",
    "    top_left = (x, y)\n",
    "    bottom_right = (x + template_width, y + template_height)\n",
    "    cv2.rectangle(img_registred_2, top_left, bottom_right, (0, 255, 0), 5)\n",
    "\n",
    "# Show the result with matches highlighted\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img_registred_2)\n",
    "plt.title('Template Matching Result')\n",
    "plt.axis('off')\n",
    "\n",
    "# Adjust layout and display the result\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving an Image\n",
    "\n",
    "In this section, we'll walk through the steps to save a processed image in a specific directory using OpenCV and Python.\n",
    "\n",
    "## Steps to Save an Image\n",
    "\n",
    "1. **Check if the Image Exists**  \n",
    "   Before proceeding with saving, ensure that the image you're working with exists. If the image is `None`, an error will be raised to prevent further processing.\n",
    "\n",
    "2. **Ensure the Directory Exists**  \n",
    "   Use `os.makedirs()` to ensure the target directory where you want to save the image exists. If the directory doesn't exist, it will be created automatically.\n",
    "\n",
    "3. **Save the Image**  \n",
    "   Convert the image from RGB to BGR using `cv2.cvtColor()`. Then, use `cv2.imwrite()` to save the image to the specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'img_registred_1' or 'img_registred_2' is already created\n",
    "if img_registred_1 is None:\n",
    "    raise ValueError('Error: The image is empty or not loaded correctly!')\n",
    "\n",
    "# Copy the image to save it separately\n",
    "img_result = img_registred_1.copy()\n",
    "\n",
    "# Define the file path where the image will be saved\n",
    "file_path = '../Data/Stand_1/Eval'\n",
    "\n",
    "# Ensure that the directory exists\n",
    "os.makedirs(file_path, exist_ok=True)  # If the directory does not exist, create it\n",
    "\n",
    "# Construct the complete image path (including filename)\n",
    "img_path_out = os.path.join(file_path, 'Image_X.png')\n",
    "\n",
    "# Save the image using cv2.imwrite()\n",
    "cv2.imwrite(img_path_out, cv2.cvtColor(img_result, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Print the success message\n",
    "print(f'Image successfully saved at {img_path_out}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
