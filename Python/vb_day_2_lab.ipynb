{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Bootcamp - Day 2: Practical Application\n",
    "\n",
    "### Description of the Practical App.\n",
    "\n",
    "The aim of this practical application is to integrate an object detection method into a specific part of the code to identify objects in images captured by the Basler camera, by connecting to a live camera or by loading an image from a file. The YOLO detection model will be used to detect and highlight the INTEMAC logo in the captured image, ensuring accurate and efficient identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "In this first step, we import the necessary libraries that will be used throughout this practical app.:\n",
    "\n",
    "- **OpenCV (`cv2`)**: This is the main library weâ€™ll use for image processing tasks, such as reading, displaying, and manipulating images.\n",
    "- **OS (`os`)**: This helps with file and directory operations, allowing us to load and save images from specific locations on your computer.\n",
    "- **Ultralytics (`YOLO`)**: This library provides real-time object detection and image segmentation capabilities. It enables us to use the YOLO model for accurate and efficient object detection.\n",
    "- **Utilities.Camera (`Basler_Cls`)**: The `Basler_Cls` class is designed to interface with Basler cameras using the `pypylon` library. It allows us to configure the camera, capture images, and release resources when done.\n",
    "\n",
    "This is the foundation for a smooth YOLO-based object detection workflow, and with these tools, we can start detecting objects in images using AI in an interactive and efficient way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "# OpenCV library for computer vision tasks\n",
    "import cv2\n",
    "\n",
    "# OS module for file handling and accessing directories\n",
    "import os\n",
    "\n",
    "# Ultralytics (Real-time object detection and image segmentation \n",
    "# model) [pip install ultralytics]\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Library to work with Basler cameras\n",
    "from Utilities.Camera import Basler_Cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Object Detection Using Basler Camera and VMR Lighting\n",
    "\n",
    "## Practical Setup\n",
    "\n",
    "- **Camera Model**: Basler a2A2448-23gcPRO GigE Camera \n",
    "- **Lighting**: VMR-11566 Multi Angle Ring Light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to configure a **Basler camera (a2A2448-23gcPRO)** with custom settings, capture an image, and perform object detection using YOLO. The system is equipped with the **VMR-11566W lighting** for optimal illumination in **stand no. 1**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom camera configuration\n",
    "custom_cfg = {\n",
    "    'exposure_time': 5000,\n",
    "    'gain': 15,\n",
    "    'balance_ratios': {'Red': 1.3, 'Green': 1.0, 'Blue': 1.1},\n",
    "    'pixel_format': 'BayerRG8'\n",
    "}\n",
    "\n",
    "# Initialize and configure the Basler camera\n",
    "Basler_Cam_Id_1 = Basler_Cls(config=custom_cfg)\n",
    "\n",
    "# Capture a single image\n",
    "img_raw = Basler_Cam_Id_1.Capture()\n",
    "if img_raw is not None:\n",
    "    # Convert the image from BGR to RGB color format\n",
    "    img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "else:\n",
    "    raise ValueError('No image captured!')\n",
    "\n",
    "# Release the camera resources\n",
    "del Basler_Cam_Id_1\n",
    "\n",
    "# Copy the original image to draw contours and bounding boxes on it\n",
    "img_registred_1 = img_rgb.copy()\n",
    "\n",
    "# Add object detection code here...\n",
    "\n",
    "# Define output image path\n",
    "output_path = os.path.join(f'../Data/Stand_1/Eval/', 'Image_X_result.png')\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "cv2.imwrite(output_path, img_raw)\n",
    "\n",
    "print(f'Result saved at: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to load the image captured by the camera on **stand no. 1** and perform object detection using YOLO.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the path to the project folder\n",
    "project_folder = os.getcwd().split('INTEMAC_Vision_Bootcamp')[0] + 'INTEMAC_Vision_Bootcamp'\n",
    "\n",
    "# Define file path for the image location\n",
    "file_path = '../Data/Stand_1/Dataset_v1/images/test/'\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "# Define the path to the image file\n",
    "img_path_in = os.path.join(file_path, 'Image_31.png')\n",
    "\n",
    "# Load the image using OpenCV\n",
    "img_raw = cv2.imread(img_path_in)\n",
    "\n",
    "# Check if the image exists\n",
    "if img_raw is None:\n",
    "    raise FileNotFoundError(f'Image not found at {img_path_in}')\n",
    "\n",
    "# Convert the image from BGR to RGB color format\n",
    "img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get image dimensions\n",
    "img_height, img_width, _ = img_rgb.shape\n",
    "\n",
    "# Load a pre-trained custom YOLO model.\n",
    "model = YOLO(f'{project_folder}/YOLO/Results/Stand_1_Dataset_v1/train_fb_True/weights/best.pt')\n",
    "\n",
    "# Predict (test) the model on a test dataset.\n",
    "results = model.predict(source=img_path_in, imgsz=640, conf=0.5, iou=0.7)\n",
    "\n",
    "# Define a dictionary for class_id to color mapping\n",
    "class_colors = {0: (0, 255, 255), 1: (255, 0, 0)}  # Yellow and Blue in BGR\n",
    "\n",
    "# If objects are detected in the image\n",
    "if results[0].boxes.shape[0] >= 1:\n",
    "    class_id = results[0].boxes.cls.cpu().numpy(); b_box = results[0].boxes.xywhn.cpu().numpy()\n",
    "    conf = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    for _, (class_id_i, b_box_i, conf_i) in enumerate(zip(class_id, b_box, conf)):\n",
    "        x_center, y_center, width, height = b_box_i\n",
    "\n",
    "        # Convert YOLO coordinates to pixel coordinates\n",
    "        x_c = int(x_center * img_width); y_c = int(y_center * img_height)\n",
    "        w = int(width * img_width); h = int(height * img_height)\n",
    "\n",
    "        # Calculate the top-left corner of the bounding box\n",
    "        x_top_left = int(x_c - w / 2); y_top_left = int(y_c - h / 2)\n",
    "        x_bottom_right = int(x_c + w / 2); y_bottom_right = int(y_c + h / 2)\n",
    "\n",
    "        # Get the bounding box color\n",
    "        class_id_color = class_colors.get(class_id_i, (0, 255, 0))  # Green as default\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(img_raw, (x_top_left, y_top_left), (x_bottom_right, y_bottom_right), class_id_color, 2)\n",
    "\n",
    "        # Put class ID and confidence score\n",
    "        label = f'Class {int(class_id_i)}: {conf_i:.2f}'\n",
    "        cv2.putText(img_raw, label, (x_top_left, y_top_left - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, class_id_color, 2)\n",
    "\n",
    "# Define output image path\n",
    "output_path = os.path.join(f'../Data/Stand_1/Eval/', 'Image_31_result.png')\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "cv2.imwrite(output_path, img_raw)\n",
    "\n",
    "print(f'Result saved at: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Object Detection Using Basler Camera and EFFI-FD Lighting\n",
    "\n",
    "## Practical Setup\n",
    "\n",
    "- **Camera Model**: Basler a2A1920-51gcPRO GigE Camera\n",
    "- **Lighting**: EFFI-FD-200-200-000 High-Power Flat Light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to configure a **Basler camera (a2A1920-51gcPRO)** with custom settings, capture an image, and perform object detection method using YOLO. The system is equipped with the **EFFI-FD-200-200-000 lighting** for optimal illumination in **stand no. 2**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom camera configuration\n",
    "custom_cfg = {\n",
    "    'exposure_time': 1000,\n",
    "    'gain': 15,\n",
    "    'balance_ratios': {'Red': 1.1, 'Green': 1.0, 'Blue': 1.3},\n",
    "    'pixel_format': 'BayerRG8'\n",
    "}\n",
    "\n",
    "# Initialize and configure the Basler camera\n",
    "Basler_Cam_Id_2 = Basler_Cls(config=custom_cfg)\n",
    "\n",
    "# Capture a single image\n",
    "img_raw = Basler_Cam_Id_2.Capture()\n",
    "if img_raw is not None:\n",
    "    # Convert the image from BGR to RGB color format\n",
    "    img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "else:\n",
    "    raise ValueError('No image captured!')\n",
    "\n",
    "# Release the camera resources\n",
    "del Basler_Cam_Id_2\n",
    "\n",
    "# Copy the original image to draw contours and bounding boxes on it\n",
    "img_registred_2 = img_rgb.copy()\n",
    "\n",
    "# Define output image path\n",
    "output_path = os.path.join(f'../Data/Stand_2/Eval/', 'Image_X_result.png')\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "cv2.imwrite(output_path, img_raw)\n",
    "\n",
    "print(f'Result saved at: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates how to load the image captured by the camera on **stand no. 2** and perform object detection using YOLO.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the path to the project folder\n",
    "project_folder = os.getcwd().split('INTEMAC_Vision_Bootcamp')[0] + 'INTEMAC_Vision_Bootcamp'\n",
    "\n",
    "# Define file path for the image location\n",
    "file_path = '../Data/Stand_2/Dataset_v1/images/test/'\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "# Define the path to the image file\n",
    "img_path_in = os.path.join(file_path, 'Image_31.png')\n",
    "\n",
    "# Load the image using OpenCV\n",
    "img_raw = cv2.imread(img_path_in)\n",
    "\n",
    "# Check if the image exists\n",
    "if img_raw is None:\n",
    "    raise FileNotFoundError(f'Image not found at {img_path_in}')\n",
    "\n",
    "# Convert the image from BGR to RGB color format\n",
    "img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get image dimensions\n",
    "img_height, img_width, _ = img_rgb.shape\n",
    "\n",
    "# Load a pre-trained custom YOLO model.\n",
    "model = YOLO(f'{project_folder}/YOLO/Results/Stand_2_Dataset_v1/train_fb_True/weights/best.pt')\n",
    "\n",
    "# Predict (test) the model on a test dataset.\n",
    "results = model.predict(source=img_path_in, imgsz=640, conf=0.5, iou=0.7)\n",
    "\n",
    "# Define a dictionary for class_id to color mapping\n",
    "class_colors = {0: (0, 255, 255), 1: (255, 0, 0)}  # Yellow and Blue in BGR\n",
    "\n",
    "# If objects are detected in the image\n",
    "if results[0].boxes.shape[0] >= 1:\n",
    "    class_id = results[0].boxes.cls.cpu().numpy(); b_box = results[0].boxes.xywhn.cpu().numpy()\n",
    "    conf = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    for _, (class_id_i, b_box_i, conf_i) in enumerate(zip(class_id, b_box, conf)):\n",
    "        x_center, y_center, width, height = b_box_i\n",
    "\n",
    "        # Convert YOLO coordinates to pixel coordinates\n",
    "        x_c = int(x_center * img_width); y_c = int(y_center * img_height)\n",
    "        w = int(width * img_width); h = int(height * img_height)\n",
    "\n",
    "        # Calculate the top-left corner of the bounding box\n",
    "        x_top_left = int(x_c - w / 2); y_top_left = int(y_c - h / 2)\n",
    "        x_bottom_right = int(x_c + w / 2); y_bottom_right = int(y_c + h / 2)\n",
    "\n",
    "        # Get the bounding box color\n",
    "        class_id_color = class_colors.get(class_id_i, (0, 255, 0))  # Green as default\n",
    "\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(img_raw, (x_top_left, y_top_left), (x_bottom_right, y_bottom_right), class_id_color, 2)\n",
    "\n",
    "        # Put class ID and confidence score\n",
    "        label = f'Class {int(class_id_i)}: {conf_i:.2f}'\n",
    "        cv2.putText(img_raw, label, (x_top_left, y_top_left - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, class_id_color, 2)\n",
    "\n",
    "# Define output image path\n",
    "output_path = os.path.join(f'../Data/Stand_2/Eval/', 'Image_31_result.png')\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "cv2.imwrite(output_path, img_raw)\n",
    "\n",
    "print(f'Result saved at: {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_vb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
